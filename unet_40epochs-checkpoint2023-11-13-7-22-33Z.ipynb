{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Instructions"
      ],
      "metadata": {},
      "id": "99b13232"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Run this notebook to:\n",
        "* Load a vgg16 model pretrained on the cifar10 dataset, from the \"pretrainedmodel\" folder.\n",
        "* Use this pretrained model to perform \"Filter Pruning via Geometric Median\". The pruned model is fine-tuned for 40 epochs. The pruning is done iteratively. So far the parameters are only zeroed out. The pruned model at this stage is saved as \"vgg_cifar10_pruned_net.pth\" in the present working directory.\n",
        "* Finally, architecture modifications are performed and the final pruned model is saved as \"vgg_cifar10_arch_pruned_net.pth\" in the present working directory."
      ],
      "metadata": {},
      "id": "d801ead2"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Selecting device"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.006789,
          "end_time": "2023-06-30T04:54:29.237311",
          "exception": false,
          "start_time": "2023-06-30T04:54:29.230522",
          "status": "completed"
        },
        "tags": []
      },
      "id": "ae9fc4fc"
    },
    {
      "cell_type": "code",
      "source": [
        "#%pip install torch \n",
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"GPU Available\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "GPU Available\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T04:54:29.251979Z",
          "iopub.status.busy": "2023-06-30T04:54:29.251220Z",
          "iopub.status.idle": "2023-06-30T04:54:33.099083Z",
          "shell.execute_reply": "2023-06-30T04:54:33.098026Z"
        },
        "gather": {
          "logged": 1702450879444
        },
        "papermill": {
          "duration": 3.858001,
          "end_time": "2023-06-30T04:54:33.101655",
          "exception": false,
          "start_time": "2023-06-30T04:54:29.243654",
          "status": "completed"
        },
        "tags": []
      },
      "id": "0ea6a8ae"
    },
    {
      "cell_type": "code",
      "source": [
        "! CUDA_VISIBLE_DEVICES=0\n",
        "#! python ./fpgmdata/testing/pruning_cifar_vgg.py  ./fpgmdata/testing/data/cifar.python --dataset cifar10 --arch vgg --save_path ./logs/vgg_prune_precfg_varience4 --rate_norm 1 --rate_dist 0.2\n",
        "! python  ./fpgmdata/testing/pruning_unet.py  ./fpgmdata/testing/data/carvana --dataset CARVANA --arch UNet --save_path ./logs/unet_pretrain/prune_precfg_epoch40_varience1 --rate_norm 1 --rate_dist 0.2 --use_pretrain --pretrain_path ./pretrainedmodel/MODEL.pth --use_state_dict --lr 0.001 --epochs 40 --use_precfg"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "save path : ./logs/unet_pretrain/prune_precfg_epoch40_varience1\n{'arch': 'UNet', 'batch_size': 1, 'cuda': True, 'data_path': './fpgmdata/testing/data/carvana', 'dataset': 'CARVANA', 'depth': 16, 'dist_type': 'l2', 'epoch_prune': 1, 'epochs': 40, 'evaluate': False, 'layer_begin': 1, 'layer_end': 1, 'layer_inter': 1, 'log_interval': 100, 'lr': 0.001, 'momentum': 0.9, 'no_cuda': False, 'pretrain_path': './pretrainedmodel/MODEL.pth', 'rate_dist': 0.2, 'rate_norm': 1.0, 'resume': '', 'save_path': './logs/unet_pretrain/prune_precfg_epoch40_varience1', 'seed': 1, 'start_epoch': 0, 'test_batch_size': 1, 'use_precfg': True, 'use_pretrain': True, 'use_state_dict': True, 'weight_decay': 0.0001}\nRandom Seed: 1\npython version : 3.8.5 (default, Sep  4 2020, 07:30:14)  [GCC 7.3.0]\ntorch  version : 1.12.0+cu102\ncudnn  version : 7605\nNorm Pruning Rate: 1.0\nDistance Pruning Rate: 0.2\nLayer Begin: 1\nLayer End: 1\nLayer Inter: 1\nEpoch prune: 1\nuse pretrain: True\nPretrain path: ./pretrainedmodel/MODEL.pth\nDist type: l2\nPre cfg: True\n100%|███████████████████████████████████████| 5088/5088 [00:59<00:00, 85.19it/s]\n=> creating model 'UNet'\n=> network :\n UNet(\n  (inc): DoubleConv(\n    (double_conv): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (down1): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down2): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down3): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (down4): Down(\n    (maxpool_conv): Sequential(\n      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (1): DoubleConv(\n        (double_conv): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n      )\n    )\n  )\n  (up1): Up(\n    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up2): Up(\n    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up3): Up(\n    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (up4): Up(\n    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n    (conv): DoubleConv(\n      (double_conv): Sequential(\n        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n      )\n    )\n  )\n  (outc): OutConv(\n    (conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n  )\n)\n=> loading pretrain model './pretrainedmodel/MODEL.pth'\n----------one epoch begin----------\nremaining ratio of pruning : Norm is 1.000000\nreducing ratio of pruning : Distance is 0.200000\ntotal remaining ratio is 0.800000\nAnswer:  tensor(0.9912, device='cuda:0')                                        \nTest Data Dice score: 0.9912203550338745\n accu before is: 0.991 %\ntorch.Size([64, 3, 3, 3])\ninc.double_conv.0.weight self.mask_index [0] 0 32 64 0.5\nself.distance_rate {0: 0.5}\ntorch.Size([64, 64, 3, 3])\ninc.double_conv.3.weight self.mask_index [0, 3] 1 64 64 0.0\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0}\ntorch.Size([128, 64, 3, 3])\ndown1.maxpool_conv.1.double_conv.0.weight self.mask_index [0, 3, 6] 2 128 128 0.0\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0}\ntorch.Size([128, 128, 3, 3])\ndown1.maxpool_conv.1.double_conv.3.weight self.mask_index [0, 3, 6, 9] 3 128 128 0.0\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0}\ntorch.Size([256, 128, 3, 3])\ndown2.maxpool_conv.1.double_conv.0.weight self.mask_index [0, 3, 6, 9, 12] 4 256 256 0.0\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0}\ntorch.Size([256, 256, 3, 3])\ndown2.maxpool_conv.1.double_conv.3.weight self.mask_index [0, 3, 6, 9, 12, 15] 5 256 256 0.0\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0}\ntorch.Size([512, 256, 3, 3])\ndown3.maxpool_conv.1.double_conv.0.weight self.mask_index [0, 3, 6, 9, 12, 15, 18] 6 256 512 0.5\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5}\ntorch.Size([512, 512, 3, 3])\ndown3.maxpool_conv.1.double_conv.3.weight self.mask_index [0, 3, 6, 9, 12, 15, 18, 21] 7 256 512 0.5\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5, 19: 1, 20: 1, 21: 0.5}\ntorch.Size([1024, 512, 3, 3])\ndown4.maxpool_conv.1.double_conv.0.weight self.mask_index [0, 3, 6, 9, 12, 15, 18, 21, 24] 8 256 1024 0.75\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5, 19: 1, 20: 1, 21: 0.5, 22: 1, 23: 1, 24: 0.75}\ntorch.Size([1024, 1024, 3, 3])\ndown4.maxpool_conv.1.double_conv.3.weight self.mask_index [0, 3, 6, 9, 12, 15, 18, 21, 24, 27] 9 256 1024 0.75\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5, 19: 1, 20: 1, 21: 0.5, 22: 1, 23: 1, 24: 0.75, 25: 1, 26: 1, 27: 0.75}\ntorch.Size([1024, 512, 2, 2])\nup1.up.weight self.mask_index [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30] 10 256 1024 0.75\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5, 19: 1, 20: 1, 21: 0.5, 22: 1, 23: 1, 24: 0.75, 25: 1, 26: 1, 27: 0.75, 28: 1, 29: 1, 30: 0.75}\ntorch.Size([512, 1024, 3, 3])\nup1.conv.double_conv.0.weight self.mask_index [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 32] 11 256 512 0.5\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5, 19: 1, 20: 1, 21: 0.5, 22: 1, 23: 1, 24: 0.75, 25: 1, 26: 1, 27: 0.75, 28: 1, 29: 1, 30: 0.75, 31: 1, 32: 0.5}\ntorch.Size([512, 512, 3, 3])\nup1.conv.double_conv.3.weight self.mask_index [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 32, 35] 12 256 512 0.5\nself.distance_rate {0: 0.5, 1: 1, 2: 1, 3: 0.0, 4: 1, 5: 1, 6: 0.0, 7: 1, 8: 1, 9: 0.0, 10: 1, 11: 1, 12: 0.0, 13: 1, 14: 1, 15: 0.0, 16: 1, 17: 1, 18: 0.5, 19: 1, 20: 1, 21: 0.5, 22: 1, 23: 1, 24: 0.75, 25: 1, 26: 1, 27: 0.75, 28: 1, 29: 1, 30: 0.75, 31: 1, 32: 0.5, 33: 1, 34: 1, 35: 0.5}\ntorch.Size([512, 256, 2, 2])\nTraceback (most recent call last):\n  File \"./fpgmdata/testing/pruning_unet.py\", line 598, in <module>\n    main()\n  File \"./fpgmdata/testing/pruning_unet.py\", line 188, in main\n    m.init_mask(args.rate_norm, args.rate_dist, args.dist_type)\n  File \"./fpgmdata/testing/pruning_unet.py\", line 537, in init_mask\n    self.init_rate(rate_norm_per_layer, rate_dist_per_layer, pre_cfg=args.use_precfg)\n  File \"./fpgmdata/testing/pruning_unet.py\", line 515, in init_rate\n    self.distance_rate[index] = 1 - cfg[cfg_index] / item[1].size()[0]\nIndexError: list index out of range\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T04:54:33.115979Z",
          "iopub.status.busy": "2023-06-30T04:54:33.115483Z",
          "iopub.status.idle": "2023-06-30T05:21:19.314906Z",
          "shell.execute_reply": "2023-06-30T05:21:19.313647Z"
        },
        "gather": {
          "logged": 1702447825334
        },
        "papermill": {
          "duration": 1606.209182,
          "end_time": "2023-06-30T05:21:19.317449",
          "exception": false,
          "start_time": "2023-06-30T04:54:33.108267",
          "status": "completed"
        },
        "tags": []
      },
      "id": "e2157c51"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "sys.path.append(\"./fpgmdata/testing\")\n",
        "import models\n",
        "\n",
        "unpruned_model = models.__dict__['UNet'](n_channels=3, n_classes=2)\n",
        "\n",
        "checkpoint = torch.load(\"./pretrainedmodel/MODEL.pth\", map_location=device)\n",
        "mask_values = checkpoint.pop('mask_values', [0, 1])\n",
        "unpruned_model.load_state_dict(checkpoint)\n",
        "\n",
        "# unpruned_model.load_state_dict(checkpoint['state_dict'])\n",
        "unpruned_model.to(device)\n",
        "\n",
        "# Print the number of layers\n",
        "num_layers = len(list(unpruned_model.children()))\n",
        "print(f\"Number of layers in the UNet model: {num_layers}\")\n",
        "\n",
        "# Print the names of layers\n",
        "print(\"Names of layers:\")\n",
        "for name, layer in unpruned_model.named_children():\n",
        "    print(f\"{name}: {layer}\")\n",
        "\n",
        "total = 0\n",
        "print('Trainable parameters:')\n",
        "\n",
        "for n, module in unpruned_model.named_modules():\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        for name, param in module.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(name, '\\t', param.numel())\n",
        "                total += param.numel()\n",
        "print()\n",
        "print('Total', '\\t', total)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Trainable parameters:\nweight \t 1728\nweight \t 36864\nweight \t 73728\nweight \t 147456\nweight \t 294912\nweight \t 589824\nweight \t 1179648\nweight \t 2359296\nweight \t 4718592\nweight \t 9437184\nweight \t 4718592\nweight \t 2359296\nweight \t 1179648\nweight \t 589824\nweight \t 294912\nweight \t 147456\nweight \t 73728\nweight \t 36864\nweight \t 128\nbias \t 2\n\nTotal \t 28239682\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:21:19.681472Z",
          "iopub.status.busy": "2023-06-30T05:21:19.679687Z",
          "iopub.status.idle": "2023-06-30T05:21:21.698924Z",
          "shell.execute_reply": "2023-06-30T05:21:21.697051Z"
        },
        "gather": {
          "logged": 1702450888586
        },
        "papermill": {
          "duration": 2.197895,
          "end_time": "2023-06-30T05:21:21.701289",
          "exception": false,
          "start_time": "2023-06-30T05:21:19.503394",
          "status": "completed"
        },
        "tags": []
      },
      "id": "dcb21885"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# General function to test a model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.175859,
          "end_time": "2023-06-30T05:21:22.058313",
          "exception": false,
          "start_time": "2023-06-30T05:21:21.882454",
          "status": "completed"
        },
        "tags": []
      },
      "id": "2fd31210"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def test_model(model):\n",
        "    model.eval()\n",
        "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "    timings = []\n",
        "    #GPU-WARM-UP\n",
        "    i=0\n",
        "    for data in testloader:\n",
        "        if(i>1000):\n",
        "            break\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        _ = model(images)\n",
        "        i += 1\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            starter.record()\n",
        "            outputs = model(images)\n",
        "            ender.record()\n",
        "            \n",
        "            # WAIT FOR GPU SYNC\n",
        "            torch.cuda.synchronize()\n",
        "            curr_time = starter.elapsed_time(ender)\n",
        "            timings.append(curr_time)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: '+str(100 * correct / total))\n",
        "    \n",
        "    tot = np.sum(timings)\n",
        "    mean_syn_per_batch = np.sum(timings) / len(timings)\n",
        "    std_syn_per_batch = np.std(timings)\n",
        "    print(\"Total inference time for test data: \"+str(tot))\n",
        "    print(\"Mean inference time per test batch: \"+str(mean_syn_per_batch))\n",
        "    print(\"Standard deviation of inference times per batch: \"+str(std_syn_per_batch))\n",
        "    model.train()"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:21:22.466002Z",
          "iopub.status.busy": "2023-06-30T05:21:22.465657Z",
          "iopub.status.idle": "2023-06-30T05:21:22.476943Z",
          "shell.execute_reply": "2023-06-30T05:21:22.476101Z"
        },
        "gather": {
          "logged": 1701080650113
        },
        "papermill": {
          "duration": 0.240732,
          "end_time": "2023-06-30T05:21:22.478927",
          "exception": false,
          "start_time": "2023-06-30T05:21:22.238195",
          "status": "completed"
        },
        "tags": []
      },
      "id": "0fd50764"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Loading and normalizing images using TorchVision\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.177495,
          "end_time": "2023-06-30T05:21:22.830425",
          "exception": false,
          "start_time": "2023-06-30T05:21:22.652930",
          "status": "completed"
        },
        "tags": []
      },
      "id": "7552b4d6"
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:21:23.191289Z",
          "iopub.status.busy": "2023-06-30T05:21:23.190919Z",
          "iopub.status.idle": "2023-06-30T05:21:23.299996Z",
          "shell.execute_reply": "2023-06-30T05:21:23.299073Z"
        },
        "gather": {
          "logged": 1701080650312
        },
        "papermill": {
          "duration": 0.292777,
          "end_time": "2023-06-30T05:21:23.302246",
          "exception": false,
          "start_time": "2023-06-30T05:21:23.009469",
          "status": "completed"
        },
        "tags": []
      },
      "id": "93236498"
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
        "                                 transforms.Pad(4),\n",
        "                                 transforms.RandomCrop(32),\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                             ]),\n",
        "                                        download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ]),\n",
        "                                       download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset,\n",
        "                                         batch_size=32,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "URLError",
          "evalue": "<urlopen error [Errno 0] Error>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:1350\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1350\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1255\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1255\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1301\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1250\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1010\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1010\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:950\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1424\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1422\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1424\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1309\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 0] Error",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomCrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomHorizontalFlip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.4914\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4822\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4465\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2023\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1994\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2010\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     12\u001b[0m testset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     13\u001b[0m             transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     14\u001b[0m             transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.4914\u001b[39m, \u001b[38;5;241m0.4822\u001b[39m, \u001b[38;5;241m0.4465\u001b[39m), (\u001b[38;5;241m0.2023\u001b[39m, \u001b[38;5;241m0.1994\u001b[39m, \u001b[38;5;241m0.2010\u001b[39m))\n\u001b[1;32m     15\u001b[0m             ]),\n\u001b[1;32m     16\u001b[0m                                        download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset not found or corrupted.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     69\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m You can use download=True to download it\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchvision/datasets/cifar.py:143\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchvision/datasets/utils.py:316\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    314\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 316\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(archive, extract_root))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchvision/datasets/utils.py:124\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# expand redirect chain if needed\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43m_get_redirect_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_redirect_hops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# check if file is located on Google Drive\u001b[39;00m\n\u001b[1;32m    127\u001b[0m file_id \u001b[38;5;241m=\u001b[39m _get_google_drive_file_id(url)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torchvision/datasets/utils.py:75\u001b[0m, in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     72\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT}\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_hops \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m==\u001b[39m url \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    528\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:1393\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/urllib/request.py:1353\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1351\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1353\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1354\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 0] Error>"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:21:23.662003Z",
          "iopub.status.busy": "2023-06-30T05:21:23.661209Z",
          "iopub.status.idle": "2023-06-30T05:22:03.505187Z",
          "shell.execute_reply": "2023-06-30T05:22:03.504251Z"
        },
        "gather": {
          "logged": 1701080652092
        },
        "papermill": {
          "duration": 40.025602,
          "end_time": "2023-06-30T05:22:03.507490",
          "exception": false,
          "start_time": "2023-06-30T05:21:23.481888",
          "status": "completed"
        },
        "tags": []
      },
      "id": "5b345ead"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "defaultcfg = {\n",
        "    11 : [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
        "    13 : [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n",
        "    16 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n",
        "    19 : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n",
        "}\n",
        "\n",
        "class vgg(nn.Module):\n",
        "    def __init__(self, dataset='cifar10', depth=16, init_weights=True, cfg=None):\n",
        "        super(vgg, self).__init__()\n",
        "        if cfg is None:\n",
        "            cfg = defaultcfg[depth]\n",
        "\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.feature = self.make_layers(cfg, True)\n",
        "\n",
        "        if dataset == 'cifar10':\n",
        "            num_classes = 10\n",
        "        elif dataset == 'cifar100':\n",
        "            num_classes = 100\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(cfg[-1], 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def make_layers(self, cfg, batch_norm=False):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in cfg:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
        "                if batch_norm:\n",
        "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        x = nn.AvgPool2d(2)(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        y = self.classifier(x)\n",
        "        return y\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(0.5)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:03.977498Z",
          "iopub.status.busy": "2023-06-30T05:22:03.976899Z",
          "iopub.status.idle": "2023-06-30T05:22:04.019642Z",
          "shell.execute_reply": "2023-06-30T05:22:04.013991Z"
        },
        "gather": {
          "logged": 1701080652528
        },
        "papermill": {
          "duration": 0.288491,
          "end_time": "2023-06-30T05:22:04.023170",
          "exception": false,
          "start_time": "2023-06-30T05:22:03.734679",
          "status": "completed"
        },
        "tags": []
      },
      "id": "b7e5bf66"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Testing the accuracy of the unpruned model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.219714,
          "end_time": "2023-06-30T05:22:04.465457",
          "exception": false,
          "start_time": "2023-06-30T05:22:04.245743",
          "status": "completed"
        },
        "tags": []
      },
      "id": "ecf51ae5"
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(unpruned_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:04.907267Z",
          "iopub.status.busy": "2023-06-30T05:22:04.906718Z",
          "iopub.status.idle": "2023-06-30T05:22:13.760589Z",
          "shell.execute_reply": "2023-06-30T05:22:13.758424Z"
        },
        "gather": {
          "logged": 1701080652596
        },
        "papermill": {
          "duration": 9.071557,
          "end_time": "2023-06-30T05:22:13.763114",
          "exception": false,
          "start_time": "2023-06-30T05:22:04.691557",
          "status": "completed"
        },
        "tags": []
      },
      "id": "02d69034"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Loading the pruned (only zeroed out) model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.209684,
          "end_time": "2023-06-30T05:22:14.250969",
          "exception": false,
          "start_time": "2023-06-30T05:22:14.041285",
          "status": "completed"
        },
        "tags": []
      },
      "id": "d08a6b07"
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model = vgg().to(device)\n",
        "\n",
        "pruned_model.load_state_dict(torch.load(\"./logs/vgg_pretrain/prune_precfg_epoch40_varience1/checkpoint.pth.tar\")['state_dict'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:14.672091Z",
          "iopub.status.busy": "2023-06-30T05:22:14.671651Z",
          "iopub.status.idle": "2023-06-30T05:22:15.060339Z",
          "shell.execute_reply": "2023-06-30T05:22:15.059425Z"
        },
        "gather": {
          "logged": 1701080652615
        },
        "papermill": {
          "duration": 0.604377,
          "end_time": "2023-06-30T05:22:15.062408",
          "exception": false,
          "start_time": "2023-06-30T05:22:14.458031",
          "status": "completed"
        },
        "tags": []
      },
      "id": "47b67eee"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Saving the pruned (only zeroed out) model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.211163,
          "end_time": "2023-06-30T05:22:15.482682",
          "exception": false,
          "start_time": "2023-06-30T05:22:15.271519",
          "status": "completed"
        },
        "tags": []
      },
      "id": "0c54dae6"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(pruned_model, './vgg_cifar10_pruned_net.pth') # without .state_dict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:15.902411Z",
          "iopub.status.busy": "2023-06-30T05:22:15.901966Z",
          "iopub.status.idle": "2023-06-30T05:22:15.995020Z",
          "shell.execute_reply": "2023-06-30T05:22:15.994016Z"
        },
        "gather": {
          "logged": 1701080652633
        },
        "papermill": {
          "duration": 0.310555,
          "end_time": "2023-06-30T05:22:15.997574",
          "exception": false,
          "start_time": "2023-06-30T05:22:15.687019",
          "status": "completed"
        },
        "tags": []
      },
      "id": "59e5e455"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Let's test the accuracy of the pruned (only zeroed out) model"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.205471,
          "end_time": "2023-06-30T05:22:16.413805",
          "exception": false,
          "start_time": "2023-06-30T05:22:16.208334",
          "status": "completed"
        },
        "tags": []
      },
      "id": "b9d9b20c"
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(pruned_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:16.834743Z",
          "iopub.status.busy": "2023-06-30T05:22:16.834382Z",
          "iopub.status.idle": "2023-06-30T05:22:24.649645Z",
          "shell.execute_reply": "2023-06-30T05:22:24.648374Z"
        },
        "gather": {
          "logged": 1701080652649
        },
        "papermill": {
          "duration": 8.032044,
          "end_time": "2023-06-30T05:22:24.652227",
          "exception": false,
          "start_time": "2023-06-30T05:22:16.620183",
          "status": "completed"
        },
        "tags": []
      },
      "id": "69755cf1"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Changing the architecture"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.216207,
          "end_time": "2023-06-30T05:22:25.093057",
          "exception": false,
          "start_time": "2023-06-30T05:22:24.876850",
          "status": "completed"
        },
        "tags": []
      },
      "id": "9de7c4a1"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-pruning\n",
        "import torch_pruning as tp\n",
        "    \n",
        "for name, module in pruned_model.named_modules():\n",
        "    if isinstance(module, torch.nn.Conv2d): #Iterating over all the conv2d layers of the model\n",
        "        channel_indices = [] #Stores indices of the channels to prune within this conv layer\n",
        "        t = module.weight.clone().detach()\n",
        "        t = t.reshape(t.shape[0], -1)\n",
        "        z = torch.all(t == 0, dim=1)\n",
        "        z = z.tolist()\n",
        "        \n",
        "        for i, flag in enumerate(z):\n",
        "            if(flag):\n",
        "                channel_indices.append(i)\n",
        "\n",
        "        if(channel_indices == []):\n",
        "            continue\n",
        "        \n",
        "        # 1. build dependency graph for vgg\n",
        "        DG = tp.DependencyGraph().build_dependency(pruned_model, example_inputs=torch.randn(1,3,32,32).to(device))\n",
        "\n",
        "        # 2. Specify the to-be-pruned channels. Here we prune those channels indexed by idxs.\n",
        "        group = DG.get_pruning_group(module, tp.prune_conv_out_channels, idxs=channel_indices)\n",
        "        #print(group)\n",
        "\n",
        "        # 3. prune all grouped layers that are coupled with the conv layer (included).\n",
        "        if DG.check_pruning_group(group): # avoid full pruning, i.e., channels=0.\n",
        "            group.prune()\n",
        "    \n",
        "# 4. Save & Load\n",
        "pruned_model.zero_grad() # We don't want to store gradient information\n",
        "torch.save(pruned_model, './vgg_cifar10_arch_pruned_net.pth') # without .state_dict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:25.519296Z",
          "iopub.status.busy": "2023-06-30T05:22:25.518801Z",
          "iopub.status.idle": "2023-06-30T05:22:39.141849Z",
          "shell.execute_reply": "2023-06-30T05:22:39.140723Z"
        },
        "gather": {
          "logged": 1701080652664
        },
        "papermill": {
          "duration": 13.839724,
          "end_time": "2023-06-30T05:22:39.144880",
          "exception": false,
          "start_time": "2023-06-30T05:22:25.305156",
          "status": "completed"
        },
        "tags": []
      },
      "id": "6e405495"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Let's test the accuracy of the pruned model after the architecture modifications"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.217711,
          "end_time": "2023-06-30T05:22:39.590133",
          "exception": false,
          "start_time": "2023-06-30T05:22:39.372422",
          "status": "completed"
        },
        "tags": []
      },
      "id": "edda7498"
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(pruned_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:40.024547Z",
          "iopub.status.busy": "2023-06-30T05:22:40.023374Z",
          "iopub.status.idle": "2023-06-30T05:22:47.157625Z",
          "shell.execute_reply": "2023-06-30T05:22:47.155940Z"
        },
        "gather": {
          "logged": 1701080652690
        },
        "papermill": {
          "duration": 7.355547,
          "end_time": "2023-06-30T05:22:47.160045",
          "exception": false,
          "start_time": "2023-06-30T05:22:39.804498",
          "status": "completed"
        },
        "tags": []
      },
      "id": "15f22780"
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Arch pruned model reload check"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.20658,
          "end_time": "2023-06-30T05:22:47.581742",
          "exception": false,
          "start_time": "2023-06-30T05:22:47.375162",
          "status": "completed"
        },
        "tags": []
      },
      "id": "764f8c19"
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded_model = torch.load('./vgg_cifar10_arch_pruned_net.pth')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:48.000350Z",
          "iopub.status.busy": "2023-06-30T05:22:47.999924Z",
          "iopub.status.idle": "2023-06-30T05:22:48.038650Z",
          "shell.execute_reply": "2023-06-30T05:22:48.037722Z"
        },
        "gather": {
          "logged": 1701080652712
        },
        "papermill": {
          "duration": 0.251362,
          "end_time": "2023-06-30T05:22:48.041058",
          "exception": false,
          "start_time": "2023-06-30T05:22:47.789696",
          "status": "completed"
        },
        "tags": []
      },
      "id": "e698a75d"
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(reloaded_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-06-30T05:22:48.456787Z",
          "iopub.status.busy": "2023-06-30T05:22:48.456412Z",
          "iopub.status.idle": "2023-06-30T05:22:56.220949Z",
          "shell.execute_reply": "2023-06-30T05:22:56.219699Z"
        },
        "gather": {
          "logged": 1701080652727
        },
        "papermill": {
          "duration": 7.975207,
          "end_time": "2023-06-30T05:22:56.223048",
          "exception": false,
          "start_time": "2023-06-30T05:22:48.247841",
          "status": "completed"
        },
        "tags": []
      },
      "id": "2012a059"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "papermill": {
      "output_path": "__notebook__.ipynb",
      "default_parameters": {},
      "start_time": "2023-06-30T04:54:17.625084",
      "parameters": {},
      "environment_variables": {},
      "exception": null,
      "end_time": "2023-06-30T05:22:58.063433",
      "duration": 1720.438349,
      "version": "2.4.0",
      "input_path": "__notebook__.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}